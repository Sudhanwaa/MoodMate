{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\MoodMate\\code\\meta_data_creation.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/MoodMate/code/meta_data_creation.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/MoodMate/code/meta_data_creation.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m  \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/MoodMate/code/meta_data_creation.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlibrosa\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/MoodMate/code/meta_data_creation.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/MoodMate/code/meta_data_creation.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m  \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os \n",
    "from  tqdm import tqdm\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow  as tf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a metadata File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"audio_metadata.csv\", 'w') as file:\n",
    "  writer = csv.writer(file)   \n",
    "  writer.writerow([\"0\", \"1\",\"2\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Columns for the metadata File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('audio_metadata.csv', header=None)\n",
    "df.rename(columns={0: 'audio_name', 1: 'audio_class',2: \"audio_class_name\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_class</th>\n",
       "      <th>audio_class_name</th>\n",
       "      <th>audio_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry_10.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry_100.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry_1000.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry_1001.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   audio_class audio_class_name      audio_name\n",
       "1          1.0            angry     angry_1.wav\n",
       "2          1.0            angry    angry_10.wav\n",
       "3          1.0            angry   angry_100.wav\n",
       "4          1.0            angry  angry_1000.wav\n",
       "5          1.0            angry  angry_1001.wav"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('audio_metadata.csv', header=None)\n",
    "\n",
    "path=\"D:/Projects/MoodMate/speech_dataset\"\n",
    "count=0\n",
    "for emotion in os.listdir(path):\n",
    "    count+=1\n",
    "    for audio in os.listdir(path + \"/\" + emotion):\n",
    "        new_row = {'audio_name': audio, 'audio_class': count, 'audio_class_name': emotion}\n",
    "        df = df.append(new_row, ignore_index=True)\n",
    "        \n",
    "df=df.drop([0,1,2],axis=1)\n",
    "df.head()\n",
    "\n",
    "\n",
    "df=df.iloc[1:]\n",
    "df.to_csv(\"audio_metadata.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>audio_class</th>\n",
       "      <th>audio_class_name</th>\n",
       "      <th>audio_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry_10.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry_100.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry_1000.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>angry</td>\n",
       "      <td>angry_1001.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  audio_class audio_class_name      audio_name\n",
       "0           1          1.0            angry     angry_1.wav\n",
       "1           2          1.0            angry    angry_10.wav\n",
       "2           3          1.0            angry   angry_100.wav\n",
       "3           4          1.0            angry  angry_1000.wav\n",
       "4           5          1.0            angry  angry_1001.wav"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata=pd.read_csv(\"audio_metadata.csv\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 94)\n"
     ]
    }
   ],
   "source": [
    "signal,sr = librosa.load(\"sudi.wav\")\n",
    "mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=40)\n",
    "print(mfccs.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20240it [09:54, 34.07it/s]\n"
     ]
    }
   ],
   "source": [
    "extracted_features=[]\n",
    "\n",
    "dataset_path=\"D:/Projects/MoodMate/speech_dataset\"\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    file_name=dataset_path + \"/\" + row[\"audio_class_name\"] + \"/\" + row[\"audio_name\"]\n",
    "    final_class_labels=row[\"audio_class_name\"]\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-362.86337, 31.40439, 0.7086624, 21.240759, -...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-337.9935, 22.65596, -9.750982, 16.62628, -18...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-344.77017, 14.45916, -7.1472893, 16.655972, ...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-565.93616, 59.726994, -15.802911, 9.832316, ...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-386.13574, 9.975171, -1.291482, 0.15957417, ...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature  class\n",
       "0  [-362.86337, 31.40439, 0.7086624, 21.240759, -...  angry\n",
       "1  [-337.9935, 22.65596, -9.750982, 16.62628, -18...  angry\n",
       "2  [-344.77017, 14.45916, -7.1472893, 16.655972, ...  angry\n",
       "3  [-565.93616, 59.726994, -15.802911, 9.832316, ...  angry\n",
       "4  [-386.13574, 9.975171, -1.291482, 0.15957417, ...  angry"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4048, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Split the dataset into independent and dependent dataset\n",
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "Y=np.array(extracted_features_df['class'].tolist())\n",
    "Y=np.array(pd.get_dummies(Y))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=0)\n",
    "\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### No of classes\n",
    "num_labels=Y.shape[1]\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(200,input_shape=(40,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 200)               8200      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 200)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 357       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 7)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,707\n",
      "Trainable params: 33,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "245/253 [============================>.] - ETA: 0s - loss: 1.9164 - accuracy: 0.2064\n",
      "Epoch 1: val_loss improved from inf to 1.54002, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 2s 3ms/step - loss: 1.9083 - accuracy: 0.2084 - val_loss: 1.5400 - val_accuracy: 0.4002\n",
      "Epoch 2/150\n",
      "245/253 [============================>.] - ETA: 0s - loss: 1.4883 - accuracy: 0.4094\n",
      "Epoch 2: val_loss improved from 1.54002 to 1.12499, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 1.4843 - accuracy: 0.4120 - val_loss: 1.1250 - val_accuracy: 0.6635\n",
      "Epoch 3/150\n",
      "245/253 [============================>.] - ETA: 0s - loss: 1.1941 - accuracy: 0.5652\n",
      "Epoch 3: val_loss improved from 1.12499 to 0.89076, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 1.1909 - accuracy: 0.5665 - val_loss: 0.8908 - val_accuracy: 0.7179\n",
      "Epoch 4/150\n",
      "252/253 [============================>.] - ETA: 0s - loss: 1.0202 - accuracy: 0.6412\n",
      "Epoch 4: val_loss improved from 0.89076 to 0.76027, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 1.0202 - accuracy: 0.6413 - val_loss: 0.7603 - val_accuracy: 0.7515\n",
      "Epoch 5/150\n",
      "231/253 [==========================>...] - ETA: 0s - loss: 0.9293 - accuracy: 0.6732\n",
      "Epoch 5: val_loss improved from 0.76027 to 0.67488, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.9247 - accuracy: 0.6742 - val_loss: 0.6749 - val_accuracy: 0.7727\n",
      "Epoch 6/150\n",
      "251/253 [============================>.] - ETA: 0s - loss: 0.8300 - accuracy: 0.7076\n",
      "Epoch 6: val_loss improved from 0.67488 to 0.61743, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.8297 - accuracy: 0.7073 - val_loss: 0.6174 - val_accuracy: 0.7809\n",
      "Epoch 7/150\n",
      "242/253 [===========================>..] - ETA: 0s - loss: 0.7759 - accuracy: 0.7218\n",
      "Epoch 7: val_loss improved from 0.61743 to 0.58845, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.7758 - accuracy: 0.7215 - val_loss: 0.5885 - val_accuracy: 0.7811\n",
      "Epoch 8/150\n",
      "247/253 [============================>.] - ETA: 0s - loss: 0.7437 - accuracy: 0.7316\n",
      "Epoch 8: val_loss improved from 0.58845 to 0.57627, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.7436 - accuracy: 0.7317 - val_loss: 0.5763 - val_accuracy: 0.7888\n",
      "Epoch 9/150\n",
      "243/253 [===========================>..] - ETA: 0s - loss: 0.7119 - accuracy: 0.7420\n",
      "Epoch 9: val_loss improved from 0.57627 to 0.56149, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.7101 - accuracy: 0.7429 - val_loss: 0.5615 - val_accuracy: 0.7905\n",
      "Epoch 10/150\n",
      "250/253 [============================>.] - ETA: 0s - loss: 0.6829 - accuracy: 0.7507\n",
      "Epoch 10: val_loss improved from 0.56149 to 0.55473, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.6830 - accuracy: 0.7504 - val_loss: 0.5547 - val_accuracy: 0.7950\n",
      "Epoch 11/150\n",
      "231/253 [==========================>...] - ETA: 0s - loss: 0.6796 - accuracy: 0.7509\n",
      "Epoch 11: val_loss improved from 0.55473 to 0.54889, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.6800 - accuracy: 0.7500 - val_loss: 0.5489 - val_accuracy: 0.7937\n",
      "Epoch 12/150\n",
      "248/253 [============================>.] - ETA: 0s - loss: 0.6647 - accuracy: 0.7549\n",
      "Epoch 12: val_loss improved from 0.54889 to 0.54302, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.6646 - accuracy: 0.7548 - val_loss: 0.5430 - val_accuracy: 0.7964\n",
      "Epoch 13/150\n",
      "229/253 [==========================>...] - ETA: 0s - loss: 0.6552 - accuracy: 0.7590\n",
      "Epoch 13: val_loss improved from 0.54302 to 0.53224, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.6556 - accuracy: 0.7585 - val_loss: 0.5322 - val_accuracy: 0.7984\n",
      "Epoch 14/150\n",
      "245/253 [============================>.] - ETA: 0s - loss: 0.6443 - accuracy: 0.7591\n",
      "Epoch 14: val_loss improved from 0.53224 to 0.53099, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.6432 - accuracy: 0.7590 - val_loss: 0.5310 - val_accuracy: 0.7999\n",
      "Epoch 15/150\n",
      "229/253 [==========================>...] - ETA: 0s - loss: 0.6388 - accuracy: 0.7645\n",
      "Epoch 15: val_loss improved from 0.53099 to 0.52992, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.6391 - accuracy: 0.7641 - val_loss: 0.5299 - val_accuracy: 0.8036\n",
      "Epoch 16/150\n",
      "251/253 [============================>.] - ETA: 0s - loss: 0.6286 - accuracy: 0.7641\n",
      "Epoch 16: val_loss improved from 0.52992 to 0.52411, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.6292 - accuracy: 0.7641 - val_loss: 0.5241 - val_accuracy: 0.8048\n",
      "Epoch 17/150\n",
      "231/253 [==========================>...] - ETA: 0s - loss: 0.6195 - accuracy: 0.7675\n",
      "Epoch 17: val_loss improved from 0.52411 to 0.52193, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.6207 - accuracy: 0.7668 - val_loss: 0.5219 - val_accuracy: 0.8053\n",
      "Epoch 18/150\n",
      "248/253 [============================>.] - ETA: 0s - loss: 0.6139 - accuracy: 0.7698\n",
      "Epoch 18: val_loss improved from 0.52193 to 0.51251, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.6137 - accuracy: 0.7699 - val_loss: 0.5125 - val_accuracy: 0.8043\n",
      "Epoch 19/150\n",
      "253/253 [==============================] - ETA: 0s - loss: 0.6123 - accuracy: 0.7693\n",
      "Epoch 19: val_loss improved from 0.51251 to 0.50555, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.6123 - accuracy: 0.7693 - val_loss: 0.5056 - val_accuracy: 0.8073\n",
      "Epoch 20/150\n",
      "234/253 [==========================>...] - ETA: 0s - loss: 0.5999 - accuracy: 0.7778\n",
      "Epoch 20: val_loss did not improve from 0.50555\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.6026 - accuracy: 0.7768 - val_loss: 0.5084 - val_accuracy: 0.8118\n",
      "Epoch 21/150\n",
      "230/253 [==========================>...] - ETA: 0s - loss: 0.6027 - accuracy: 0.7769\n",
      "Epoch 21: val_loss did not improve from 0.50555\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.6036 - accuracy: 0.7767 - val_loss: 0.5120 - val_accuracy: 0.8095\n",
      "Epoch 22/150\n",
      "248/253 [============================>.] - ETA: 0s - loss: 0.5947 - accuracy: 0.7837\n",
      "Epoch 22: val_loss improved from 0.50555 to 0.49992, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5934 - accuracy: 0.7839 - val_loss: 0.4999 - val_accuracy: 0.8132\n",
      "Epoch 23/150\n",
      "229/253 [==========================>...] - ETA: 0s - loss: 0.5946 - accuracy: 0.7792\n",
      "Epoch 23: val_loss did not improve from 0.49992\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5985 - accuracy: 0.7779 - val_loss: 0.5109 - val_accuracy: 0.8071\n",
      "Epoch 24/150\n",
      "230/253 [==========================>...] - ETA: 0s - loss: 0.5909 - accuracy: 0.7787\n",
      "Epoch 24: val_loss improved from 0.49992 to 0.49352, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5892 - accuracy: 0.7792 - val_loss: 0.4935 - val_accuracy: 0.8207\n",
      "Epoch 25/150\n",
      "234/253 [==========================>...] - ETA: 0s - loss: 0.5816 - accuracy: 0.7821\n",
      "Epoch 25: val_loss improved from 0.49352 to 0.49118, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.7821 - val_loss: 0.4912 - val_accuracy: 0.8165\n",
      "Epoch 26/150\n",
      "240/253 [===========================>..] - ETA: 0s - loss: 0.5827 - accuracy: 0.7824\n",
      "Epoch 26: val_loss improved from 0.49118 to 0.48640, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5867 - accuracy: 0.7812 - val_loss: 0.4864 - val_accuracy: 0.8219\n",
      "Epoch 27/150\n",
      "230/253 [==========================>...] - ETA: 0s - loss: 0.5791 - accuracy: 0.7868\n",
      "Epoch 27: val_loss did not improve from 0.48640\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5796 - accuracy: 0.7868 - val_loss: 0.4905 - val_accuracy: 0.8157\n",
      "Epoch 28/150\n",
      "234/253 [==========================>...] - ETA: 0s - loss: 0.5804 - accuracy: 0.7823\n",
      "Epoch 28: val_loss improved from 0.48640 to 0.48438, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5799 - accuracy: 0.7825 - val_loss: 0.4844 - val_accuracy: 0.8214\n",
      "Epoch 29/150\n",
      "228/253 [==========================>...] - ETA: 0s - loss: 0.5783 - accuracy: 0.7861\n",
      "Epoch 29: val_loss did not improve from 0.48438\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5775 - accuracy: 0.7858 - val_loss: 0.4874 - val_accuracy: 0.8199\n",
      "Epoch 30/150\n",
      "250/253 [============================>.] - ETA: 0s - loss: 0.5742 - accuracy: 0.7870\n",
      "Epoch 30: val_loss improved from 0.48438 to 0.47790, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5747 - accuracy: 0.7868 - val_loss: 0.4779 - val_accuracy: 0.8194\n",
      "Epoch 31/150\n",
      "244/253 [===========================>..] - ETA: 0s - loss: 0.5633 - accuracy: 0.7896\n",
      "Epoch 31: val_loss improved from 0.47790 to 0.47672, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5642 - accuracy: 0.7900 - val_loss: 0.4767 - val_accuracy: 0.8194\n",
      "Epoch 32/150\n",
      "229/253 [==========================>...] - ETA: 0s - loss: 0.5668 - accuracy: 0.7907\n",
      "Epoch 32: val_loss improved from 0.47672 to 0.47427, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5658 - accuracy: 0.7902 - val_loss: 0.4743 - val_accuracy: 0.8239\n",
      "Epoch 33/150\n",
      "251/253 [============================>.] - ETA: 0s - loss: 0.5630 - accuracy: 0.7922\n",
      "Epoch 33: val_loss did not improve from 0.47427\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5639 - accuracy: 0.7916 - val_loss: 0.4779 - val_accuracy: 0.8236\n",
      "Epoch 34/150\n",
      "232/253 [==========================>...] - ETA: 0s - loss: 0.5612 - accuracy: 0.7891\n",
      "Epoch 34: val_loss improved from 0.47427 to 0.46167, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5588 - accuracy: 0.7907 - val_loss: 0.4617 - val_accuracy: 0.8256\n",
      "Epoch 35/150\n",
      "249/253 [============================>.] - ETA: 0s - loss: 0.5510 - accuracy: 0.7941\n",
      "Epoch 35: val_loss did not improve from 0.46167\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5511 - accuracy: 0.7943 - val_loss: 0.4762 - val_accuracy: 0.8194\n",
      "Epoch 36/150\n",
      "236/253 [==========================>...] - ETA: 0s - loss: 0.5546 - accuracy: 0.7896\n",
      "Epoch 36: val_loss did not improve from 0.46167\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5532 - accuracy: 0.7903 - val_loss: 0.4672 - val_accuracy: 0.8278\n",
      "Epoch 37/150\n",
      "235/253 [==========================>...] - ETA: 0s - loss: 0.5563 - accuracy: 0.7942\n",
      "Epoch 37: val_loss improved from 0.46167 to 0.45703, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5541 - accuracy: 0.7948 - val_loss: 0.4570 - val_accuracy: 0.8261\n",
      "Epoch 38/150\n",
      "231/253 [==========================>...] - ETA: 0s - loss: 0.5513 - accuracy: 0.7948\n",
      "Epoch 38: val_loss did not improve from 0.45703\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5523 - accuracy: 0.7940 - val_loss: 0.4646 - val_accuracy: 0.8211\n",
      "Epoch 39/150\n",
      "231/253 [==========================>...] - ETA: 0s - loss: 0.5502 - accuracy: 0.7940\n",
      "Epoch 39: val_loss improved from 0.45703 to 0.45645, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5481 - accuracy: 0.7937 - val_loss: 0.4565 - val_accuracy: 0.8295\n",
      "Epoch 40/150\n",
      "243/253 [===========================>..] - ETA: 0s - loss: 0.5411 - accuracy: 0.7958\n",
      "Epoch 40: val_loss did not improve from 0.45645\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7953 - val_loss: 0.4626 - val_accuracy: 0.8303\n",
      "Epoch 41/150\n",
      "230/253 [==========================>...] - ETA: 0s - loss: 0.5420 - accuracy: 0.7990\n",
      "Epoch 41: val_loss improved from 0.45645 to 0.45042, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5425 - accuracy: 0.7992 - val_loss: 0.4504 - val_accuracy: 0.8305\n",
      "Epoch 42/150\n",
      "229/253 [==========================>...] - ETA: 0s - loss: 0.5469 - accuracy: 0.7953\n",
      "Epoch 42: val_loss did not improve from 0.45042\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5470 - accuracy: 0.7952 - val_loss: 0.4517 - val_accuracy: 0.8342\n",
      "Epoch 43/150\n",
      "251/253 [============================>.] - ETA: 0s - loss: 0.5378 - accuracy: 0.7982\n",
      "Epoch 43: val_loss did not improve from 0.45042\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7977 - val_loss: 0.4535 - val_accuracy: 0.8283\n",
      "Epoch 44/150\n",
      "229/253 [==========================>...] - ETA: 0s - loss: 0.5353 - accuracy: 0.7996\n",
      "Epoch 44: val_loss did not improve from 0.45042\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7987 - val_loss: 0.4512 - val_accuracy: 0.8379\n",
      "Epoch 45/150\n",
      "244/253 [===========================>..] - ETA: 0s - loss: 0.5440 - accuracy: 0.7961\n",
      "Epoch 45: val_loss did not improve from 0.45042\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5434 - accuracy: 0.7964 - val_loss: 0.4608 - val_accuracy: 0.8305\n",
      "Epoch 46/150\n",
      "239/253 [===========================>..] - ETA: 0s - loss: 0.5374 - accuracy: 0.8015\n",
      "Epoch 46: val_loss improved from 0.45042 to 0.44268, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5371 - accuracy: 0.8005 - val_loss: 0.4427 - val_accuracy: 0.8394\n",
      "Epoch 47/150\n",
      "251/253 [============================>.] - ETA: 0s - loss: 0.5301 - accuracy: 0.8014\n",
      "Epoch 47: val_loss improved from 0.44268 to 0.44134, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5291 - accuracy: 0.8018 - val_loss: 0.4413 - val_accuracy: 0.8402\n",
      "Epoch 48/150\n",
      "244/253 [===========================>..] - ETA: 0s - loss: 0.5388 - accuracy: 0.7999\n",
      "Epoch 48: val_loss improved from 0.44134 to 0.44089, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5382 - accuracy: 0.7998 - val_loss: 0.4409 - val_accuracy: 0.8355\n",
      "Epoch 49/150\n",
      "245/253 [============================>.] - ETA: 0s - loss: 0.5287 - accuracy: 0.8033\n",
      "Epoch 49: val_loss improved from 0.44089 to 0.43201, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5264 - accuracy: 0.8042 - val_loss: 0.4320 - val_accuracy: 0.8392\n",
      "Epoch 50/150\n",
      "250/253 [============================>.] - ETA: 0s - loss: 0.5290 - accuracy: 0.8035\n",
      "Epoch 50: val_loss improved from 0.43201 to 0.42932, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5304 - accuracy: 0.8026 - val_loss: 0.4293 - val_accuracy: 0.8394\n",
      "Epoch 51/150\n",
      "249/253 [============================>.] - ETA: 0s - loss: 0.5278 - accuracy: 0.8032\n",
      "Epoch 51: val_loss did not improve from 0.42932\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5272 - accuracy: 0.8036 - val_loss: 0.4446 - val_accuracy: 0.8379\n",
      "Epoch 52/150\n",
      "253/253 [==============================] - ETA: 0s - loss: 0.5209 - accuracy: 0.8053\n",
      "Epoch 52: val_loss did not improve from 0.42932\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5209 - accuracy: 0.8053 - val_loss: 0.4371 - val_accuracy: 0.8397\n",
      "Epoch 53/150\n",
      "240/253 [===========================>..] - ETA: 0s - loss: 0.5190 - accuracy: 0.8062\n",
      "Epoch 53: val_loss did not improve from 0.42932\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5210 - accuracy: 0.8058 - val_loss: 0.4298 - val_accuracy: 0.8397\n",
      "Epoch 54/150\n",
      "242/253 [===========================>..] - ETA: 0s - loss: 0.5274 - accuracy: 0.8006\n",
      "Epoch 54: val_loss did not improve from 0.42932\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5275 - accuracy: 0.8011 - val_loss: 0.4303 - val_accuracy: 0.8414\n",
      "Epoch 55/150\n",
      "251/253 [============================>.] - ETA: 0s - loss: 0.5169 - accuracy: 0.8079\n",
      "Epoch 55: val_loss improved from 0.42932 to 0.42308, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5168 - accuracy: 0.8080 - val_loss: 0.4231 - val_accuracy: 0.8407\n",
      "Epoch 56/150\n",
      "231/253 [==========================>...] - ETA: 0s - loss: 0.5224 - accuracy: 0.8076\n",
      "Epoch 56: val_loss did not improve from 0.42308\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5220 - accuracy: 0.8071 - val_loss: 0.4294 - val_accuracy: 0.8444\n",
      "Epoch 57/150\n",
      "249/253 [============================>.] - ETA: 0s - loss: 0.5148 - accuracy: 0.8075\n",
      "Epoch 57: val_loss did not improve from 0.42308\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5144 - accuracy: 0.8077 - val_loss: 0.4232 - val_accuracy: 0.8404\n",
      "Epoch 58/150\n",
      "232/253 [==========================>...] - ETA: 0s - loss: 0.5127 - accuracy: 0.8070\n",
      "Epoch 58: val_loss did not improve from 0.42308\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5137 - accuracy: 0.8068 - val_loss: 0.4241 - val_accuracy: 0.8370\n",
      "Epoch 59/150\n",
      "242/253 [===========================>..] - ETA: 0s - loss: 0.5127 - accuracy: 0.8066\n",
      "Epoch 59: val_loss improved from 0.42308 to 0.41779, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5123 - accuracy: 0.8064 - val_loss: 0.4178 - val_accuracy: 0.8451\n",
      "Epoch 60/150\n",
      "248/253 [============================>.] - ETA: 0s - loss: 0.5114 - accuracy: 0.8116\n",
      "Epoch 60: val_loss did not improve from 0.41779\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5120 - accuracy: 0.8116 - val_loss: 0.4214 - val_accuracy: 0.8463\n",
      "Epoch 61/150\n",
      "240/253 [===========================>..] - ETA: 0s - loss: 0.5107 - accuracy: 0.8093\n",
      "Epoch 61: val_loss improved from 0.41779 to 0.41681, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5103 - accuracy: 0.8091 - val_loss: 0.4168 - val_accuracy: 0.8461\n",
      "Epoch 62/150\n",
      "251/253 [============================>.] - ETA: 0s - loss: 0.5090 - accuracy: 0.8101\n",
      "Epoch 62: val_loss improved from 0.41681 to 0.41434, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5094 - accuracy: 0.8103 - val_loss: 0.4143 - val_accuracy: 0.8461\n",
      "Epoch 63/150\n",
      "246/253 [============================>.] - ETA: 0s - loss: 0.5047 - accuracy: 0.8106\n",
      "Epoch 63: val_loss improved from 0.41434 to 0.41340, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5048 - accuracy: 0.8103 - val_loss: 0.4134 - val_accuracy: 0.8449\n",
      "Epoch 64/150\n",
      "248/253 [============================>.] - ETA: 0s - loss: 0.5075 - accuracy: 0.8121\n",
      "Epoch 64: val_loss improved from 0.41340 to 0.41078, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5077 - accuracy: 0.8123 - val_loss: 0.4108 - val_accuracy: 0.8466\n",
      "Epoch 65/150\n",
      "235/253 [==========================>...] - ETA: 0s - loss: 0.5045 - accuracy: 0.8086\n",
      "Epoch 65: val_loss did not improve from 0.41078\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5051 - accuracy: 0.8085 - val_loss: 0.4155 - val_accuracy: 0.8461\n",
      "Epoch 66/150\n",
      "251/253 [============================>.] - ETA: 0s - loss: 0.5030 - accuracy: 0.8118\n",
      "Epoch 66: val_loss improved from 0.41078 to 0.41000, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5026 - accuracy: 0.8120 - val_loss: 0.4100 - val_accuracy: 0.8481\n",
      "Epoch 67/150\n",
      "228/253 [==========================>...] - ETA: 0s - loss: 0.4974 - accuracy: 0.8139\n",
      "Epoch 67: val_loss improved from 0.41000 to 0.40799, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4946 - accuracy: 0.8148 - val_loss: 0.4080 - val_accuracy: 0.8473\n",
      "Epoch 68/150\n",
      "246/253 [============================>.] - ETA: 0s - loss: 0.5037 - accuracy: 0.8114\n",
      "Epoch 68: val_loss improved from 0.40799 to 0.40573, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5037 - accuracy: 0.8118 - val_loss: 0.4057 - val_accuracy: 0.8515\n",
      "Epoch 69/150\n",
      "242/253 [===========================>..] - ETA: 0s - loss: 0.4984 - accuracy: 0.8119\n",
      "Epoch 69: val_loss did not improve from 0.40573\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4989 - accuracy: 0.8120 - val_loss: 0.4124 - val_accuracy: 0.8498\n",
      "Epoch 70/150\n",
      "231/253 [==========================>...] - ETA: 0s - loss: 0.5012 - accuracy: 0.8141\n",
      "Epoch 70: val_loss improved from 0.40573 to 0.40184, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.5010 - accuracy: 0.8149 - val_loss: 0.4018 - val_accuracy: 0.8488\n",
      "Epoch 71/150\n",
      "250/253 [============================>.] - ETA: 0s - loss: 0.4883 - accuracy: 0.8178\n",
      "Epoch 71: val_loss did not improve from 0.40184\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4882 - accuracy: 0.8179 - val_loss: 0.4062 - val_accuracy: 0.8491\n",
      "Epoch 72/150\n",
      "250/253 [============================>.] - ETA: 0s - loss: 0.5065 - accuracy: 0.8119\n",
      "Epoch 72: val_loss did not improve from 0.40184\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5060 - accuracy: 0.8122 - val_loss: 0.4078 - val_accuracy: 0.8500\n",
      "Epoch 73/150\n",
      "228/253 [==========================>...] - ETA: 0s - loss: 0.5025 - accuracy: 0.8104\n",
      "Epoch 73: val_loss did not improve from 0.40184\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.5017 - accuracy: 0.8110 - val_loss: 0.4040 - val_accuracy: 0.8500\n",
      "Epoch 74/150\n",
      "236/253 [==========================>...] - ETA: 0s - loss: 0.4875 - accuracy: 0.8189\n",
      "Epoch 74: val_loss did not improve from 0.40184\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4884 - accuracy: 0.8191 - val_loss: 0.4078 - val_accuracy: 0.8476\n",
      "Epoch 75/150\n",
      "229/253 [==========================>...] - ETA: 0s - loss: 0.4909 - accuracy: 0.8173\n",
      "Epoch 75: val_loss did not improve from 0.40184\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4933 - accuracy: 0.8163 - val_loss: 0.4071 - val_accuracy: 0.8496\n",
      "Epoch 76/150\n",
      "251/253 [============================>.] - ETA: 0s - loss: 0.4920 - accuracy: 0.8157\n",
      "Epoch 76: val_loss improved from 0.40184 to 0.38847, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4925 - accuracy: 0.8156 - val_loss: 0.3885 - val_accuracy: 0.8575\n",
      "Epoch 77/150\n",
      "247/253 [============================>.] - ETA: 0s - loss: 0.4809 - accuracy: 0.8226\n",
      "Epoch 77: val_loss improved from 0.38847 to 0.38742, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4816 - accuracy: 0.8225 - val_loss: 0.3874 - val_accuracy: 0.8575\n",
      "Epoch 78/150\n",
      "231/253 [==========================>...] - ETA: 0s - loss: 0.4856 - accuracy: 0.8194\n",
      "Epoch 78: val_loss improved from 0.38742 to 0.38410, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4837 - accuracy: 0.8203 - val_loss: 0.3841 - val_accuracy: 0.8550\n",
      "Epoch 79/150\n",
      "234/253 [==========================>...] - ETA: 0s - loss: 0.4827 - accuracy: 0.8170\n",
      "Epoch 79: val_loss did not improve from 0.38410\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4831 - accuracy: 0.8167 - val_loss: 0.4033 - val_accuracy: 0.8456\n",
      "Epoch 80/150\n",
      "249/253 [============================>.] - ETA: 0s - loss: 0.4882 - accuracy: 0.8157\n",
      "Epoch 80: val_loss did not improve from 0.38410\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4882 - accuracy: 0.8155 - val_loss: 0.3957 - val_accuracy: 0.8518\n",
      "Epoch 81/150\n",
      "232/253 [==========================>...] - ETA: 0s - loss: 0.4887 - accuracy: 0.8176\n",
      "Epoch 81: val_loss did not improve from 0.38410\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4878 - accuracy: 0.8176 - val_loss: 0.3903 - val_accuracy: 0.8520\n",
      "Epoch 82/150\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4871 - accuracy: 0.8192\n",
      "Epoch 82: val_loss did not improve from 0.38410\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4877 - accuracy: 0.8191 - val_loss: 0.4006 - val_accuracy: 0.8513\n",
      "Epoch 83/150\n",
      "251/253 [============================>.] - ETA: 0s - loss: 0.4771 - accuracy: 0.8209\n",
      "Epoch 83: val_loss did not improve from 0.38410\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.8212 - val_loss: 0.3909 - val_accuracy: 0.8530\n",
      "Epoch 84/150\n",
      "231/253 [==========================>...] - ETA: 0s - loss: 0.4717 - accuracy: 0.8244\n",
      "Epoch 84: val_loss did not improve from 0.38410\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4730 - accuracy: 0.8242 - val_loss: 0.3889 - val_accuracy: 0.8542\n",
      "Epoch 85/150\n",
      "246/253 [============================>.] - ETA: 0s - loss: 0.4766 - accuracy: 0.8209\n",
      "Epoch 85: val_loss did not improve from 0.38410\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4777 - accuracy: 0.8210 - val_loss: 0.3878 - val_accuracy: 0.8599\n",
      "Epoch 86/150\n",
      "253/253 [==============================] - ETA: 0s - loss: 0.4787 - accuracy: 0.8215\n",
      "Epoch 86: val_loss improved from 0.38410 to 0.38159, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4787 - accuracy: 0.8215 - val_loss: 0.3816 - val_accuracy: 0.8582\n",
      "Epoch 87/150\n",
      "247/253 [============================>.] - ETA: 0s - loss: 0.4821 - accuracy: 0.8194\n",
      "Epoch 87: val_loss did not improve from 0.38159\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4829 - accuracy: 0.8189 - val_loss: 0.3851 - val_accuracy: 0.8587\n",
      "Epoch 88/150\n",
      "239/253 [===========================>..] - ETA: 0s - loss: 0.4700 - accuracy: 0.8243\n",
      "Epoch 88: val_loss did not improve from 0.38159\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4673 - accuracy: 0.8255 - val_loss: 0.3819 - val_accuracy: 0.8572\n",
      "Epoch 89/150\n",
      "244/253 [===========================>..] - ETA: 0s - loss: 0.4690 - accuracy: 0.8221\n",
      "Epoch 89: val_loss improved from 0.38159 to 0.37852, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4686 - accuracy: 0.8218 - val_loss: 0.3785 - val_accuracy: 0.8580\n",
      "Epoch 90/150\n",
      "239/253 [===========================>..] - ETA: 0s - loss: 0.4622 - accuracy: 0.8268\n",
      "Epoch 90: val_loss improved from 0.37852 to 0.37417, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4661 - accuracy: 0.8262 - val_loss: 0.3742 - val_accuracy: 0.8584\n",
      "Epoch 91/150\n",
      "230/253 [==========================>...] - ETA: 0s - loss: 0.4736 - accuracy: 0.8226\n",
      "Epoch 91: val_loss did not improve from 0.37417\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4755 - accuracy: 0.8211 - val_loss: 0.3782 - val_accuracy: 0.8626\n",
      "Epoch 92/150\n",
      "239/253 [===========================>..] - ETA: 0s - loss: 0.4741 - accuracy: 0.8243\n",
      "Epoch 92: val_loss did not improve from 0.37417\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4761 - accuracy: 0.8231 - val_loss: 0.3866 - val_accuracy: 0.8594\n",
      "Epoch 93/150\n",
      "248/253 [============================>.] - ETA: 0s - loss: 0.4681 - accuracy: 0.8237\n",
      "Epoch 93: val_loss did not improve from 0.37417\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4685 - accuracy: 0.8237 - val_loss: 0.3788 - val_accuracy: 0.8592\n",
      "Epoch 94/150\n",
      "247/253 [============================>.] - ETA: 0s - loss: 0.4693 - accuracy: 0.8248\n",
      "Epoch 94: val_loss did not improve from 0.37417\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4687 - accuracy: 0.8249 - val_loss: 0.3782 - val_accuracy: 0.8602\n",
      "Epoch 95/150\n",
      "246/253 [============================>.] - ETA: 0s - loss: 0.4661 - accuracy: 0.8267\n",
      "Epoch 95: val_loss improved from 0.37417 to 0.37214, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4647 - accuracy: 0.8272 - val_loss: 0.3721 - val_accuracy: 0.8612\n",
      "Epoch 96/150\n",
      "251/253 [============================>.] - ETA: 0s - loss: 0.4685 - accuracy: 0.8259\n",
      "Epoch 96: val_loss improved from 0.37214 to 0.37187, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4696 - accuracy: 0.8256 - val_loss: 0.3719 - val_accuracy: 0.8624\n",
      "Epoch 97/150\n",
      "241/253 [===========================>..] - ETA: 0s - loss: 0.4767 - accuracy: 0.8215\n",
      "Epoch 97: val_loss improved from 0.37187 to 0.36778, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4745 - accuracy: 0.8219 - val_loss: 0.3678 - val_accuracy: 0.8666\n",
      "Epoch 98/150\n",
      "236/253 [==========================>...] - ETA: 0s - loss: 0.4635 - accuracy: 0.8258\n",
      "Epoch 98: val_loss did not improve from 0.36778\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4659 - accuracy: 0.8242 - val_loss: 0.3736 - val_accuracy: 0.8617\n",
      "Epoch 99/150\n",
      "253/253 [==============================] - ETA: 0s - loss: 0.4612 - accuracy: 0.8295\n",
      "Epoch 99: val_loss did not improve from 0.36778\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4612 - accuracy: 0.8295 - val_loss: 0.3739 - val_accuracy: 0.8614\n",
      "Epoch 100/150\n",
      "250/253 [============================>.] - ETA: 0s - loss: 0.4650 - accuracy: 0.8281\n",
      "Epoch 100: val_loss did not improve from 0.36778\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.8278 - val_loss: 0.3756 - val_accuracy: 0.8602\n",
      "Epoch 101/150\n",
      "237/253 [===========================>..] - ETA: 0s - loss: 0.4610 - accuracy: 0.8276\n",
      "Epoch 101: val_loss did not improve from 0.36778\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4595 - accuracy: 0.8283 - val_loss: 0.3765 - val_accuracy: 0.8636\n",
      "Epoch 102/150\n",
      "235/253 [==========================>...] - ETA: 0s - loss: 0.4604 - accuracy: 0.8284\n",
      "Epoch 102: val_loss did not improve from 0.36778\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.8279 - val_loss: 0.3762 - val_accuracy: 0.8631\n",
      "Epoch 103/150\n",
      "229/253 [==========================>...] - ETA: 0s - loss: 0.4606 - accuracy: 0.8269\n",
      "Epoch 103: val_loss did not improve from 0.36778\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.8274 - val_loss: 0.3685 - val_accuracy: 0.8617\n",
      "Epoch 104/150\n",
      "241/253 [===========================>..] - ETA: 0s - loss: 0.4577 - accuracy: 0.8304\n",
      "Epoch 104: val_loss improved from 0.36778 to 0.36758, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4591 - accuracy: 0.8301 - val_loss: 0.3676 - val_accuracy: 0.8580\n",
      "Epoch 105/150\n",
      "253/253 [==============================] - ETA: 0s - loss: 0.4616 - accuracy: 0.8294\n",
      "Epoch 105: val_loss improved from 0.36758 to 0.36475, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4616 - accuracy: 0.8294 - val_loss: 0.3647 - val_accuracy: 0.8641\n",
      "Epoch 106/150\n",
      "249/253 [============================>.] - ETA: 0s - loss: 0.4623 - accuracy: 0.8272\n",
      "Epoch 106: val_loss did not improve from 0.36475\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4633 - accuracy: 0.8272 - val_loss: 0.3741 - val_accuracy: 0.8582\n",
      "Epoch 107/150\n",
      "241/253 [===========================>..] - ETA: 0s - loss: 0.4490 - accuracy: 0.8343\n",
      "Epoch 107: val_loss did not improve from 0.36475\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4511 - accuracy: 0.8334 - val_loss: 0.3666 - val_accuracy: 0.8631\n",
      "Epoch 108/150\n",
      "241/253 [===========================>..] - ETA: 0s - loss: 0.4562 - accuracy: 0.8286\n",
      "Epoch 108: val_loss did not improve from 0.36475\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4581 - accuracy: 0.8276 - val_loss: 0.3653 - val_accuracy: 0.8668\n",
      "Epoch 109/150\n",
      "232/253 [==========================>...] - ETA: 0s - loss: 0.4452 - accuracy: 0.8320\n",
      "Epoch 109: val_loss improved from 0.36475 to 0.35664, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4465 - accuracy: 0.8309 - val_loss: 0.3566 - val_accuracy: 0.8661\n",
      "Epoch 110/150\n",
      "243/253 [===========================>..] - ETA: 0s - loss: 0.4584 - accuracy: 0.8288\n",
      "Epoch 110: val_loss did not improve from 0.35664\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4551 - accuracy: 0.8302 - val_loss: 0.3610 - val_accuracy: 0.8671\n",
      "Epoch 111/150\n",
      "245/253 [============================>.] - ETA: 0s - loss: 0.4563 - accuracy: 0.8307\n",
      "Epoch 111: val_loss did not improve from 0.35664\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4563 - accuracy: 0.8307 - val_loss: 0.3657 - val_accuracy: 0.8599\n",
      "Epoch 112/150\n",
      "248/253 [============================>.] - ETA: 0s - loss: 0.4469 - accuracy: 0.8324\n",
      "Epoch 112: val_loss did not improve from 0.35664\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4479 - accuracy: 0.8324 - val_loss: 0.3633 - val_accuracy: 0.8604\n",
      "Epoch 113/150\n",
      "242/253 [===========================>..] - ETA: 0s - loss: 0.4518 - accuracy: 0.8330\n",
      "Epoch 113: val_loss did not improve from 0.35664\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4523 - accuracy: 0.8325 - val_loss: 0.3577 - val_accuracy: 0.8681\n",
      "Epoch 114/150\n",
      "248/253 [============================>.] - ETA: 0s - loss: 0.4542 - accuracy: 0.8319\n",
      "Epoch 114: val_loss did not improve from 0.35664\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4534 - accuracy: 0.8318 - val_loss: 0.3595 - val_accuracy: 0.8666\n",
      "Epoch 115/150\n",
      "246/253 [============================>.] - ETA: 0s - loss: 0.4464 - accuracy: 0.8335\n",
      "Epoch 115: val_loss did not improve from 0.35664\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4463 - accuracy: 0.8339 - val_loss: 0.3625 - val_accuracy: 0.8659\n",
      "Epoch 116/150\n",
      "241/253 [===========================>..] - ETA: 0s - loss: 0.4424 - accuracy: 0.8327\n",
      "Epoch 116: val_loss improved from 0.35664 to 0.34715, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4423 - accuracy: 0.8328 - val_loss: 0.3472 - val_accuracy: 0.8688\n",
      "Epoch 117/150\n",
      "228/253 [==========================>...] - ETA: 0s - loss: 0.4528 - accuracy: 0.8281\n",
      "Epoch 117: val_loss did not improve from 0.34715\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4496 - accuracy: 0.8300 - val_loss: 0.3546 - val_accuracy: 0.8691\n",
      "Epoch 118/150\n",
      "244/253 [===========================>..] - ETA: 0s - loss: 0.4460 - accuracy: 0.8364\n",
      "Epoch 118: val_loss did not improve from 0.34715\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4480 - accuracy: 0.8358 - val_loss: 0.3580 - val_accuracy: 0.8668\n",
      "Epoch 119/150\n",
      "245/253 [============================>.] - ETA: 0s - loss: 0.4516 - accuracy: 0.8289\n",
      "Epoch 119: val_loss did not improve from 0.34715\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4504 - accuracy: 0.8294 - val_loss: 0.3501 - val_accuracy: 0.8703\n",
      "Epoch 120/150\n",
      "247/253 [============================>.] - ETA: 0s - loss: 0.4432 - accuracy: 0.8345\n",
      "Epoch 120: val_loss did not improve from 0.34715\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4432 - accuracy: 0.8347 - val_loss: 0.3518 - val_accuracy: 0.8696\n",
      "Epoch 121/150\n",
      "235/253 [==========================>...] - ETA: 0s - loss: 0.4491 - accuracy: 0.8338\n",
      "Epoch 121: val_loss did not improve from 0.34715\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4500 - accuracy: 0.8333 - val_loss: 0.3598 - val_accuracy: 0.8661\n",
      "Epoch 122/150\n",
      "231/253 [==========================>...] - ETA: 0s - loss: 0.4452 - accuracy: 0.8364\n",
      "Epoch 122: val_loss did not improve from 0.34715\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4493 - accuracy: 0.8353 - val_loss: 0.3491 - val_accuracy: 0.8710\n",
      "Epoch 123/150\n",
      "235/253 [==========================>...] - ETA: 0s - loss: 0.4398 - accuracy: 0.8374\n",
      "Epoch 123: val_loss did not improve from 0.34715\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4371 - accuracy: 0.8379 - val_loss: 0.3529 - val_accuracy: 0.8668\n",
      "Epoch 124/150\n",
      "233/253 [==========================>...] - ETA: 0s - loss: 0.4482 - accuracy: 0.8334\n",
      "Epoch 124: val_loss did not improve from 0.34715\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4502 - accuracy: 0.8331 - val_loss: 0.3516 - val_accuracy: 0.8678\n",
      "Epoch 125/150\n",
      "241/253 [===========================>..] - ETA: 0s - loss: 0.4424 - accuracy: 0.8336\n",
      "Epoch 125: val_loss improved from 0.34715 to 0.34290, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4436 - accuracy: 0.8334 - val_loss: 0.3429 - val_accuracy: 0.8725\n",
      "Epoch 126/150\n",
      "245/253 [============================>.] - ETA: 0s - loss: 0.4398 - accuracy: 0.8378\n",
      "Epoch 126: val_loss did not improve from 0.34290\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4395 - accuracy: 0.8375 - val_loss: 0.3466 - val_accuracy: 0.8757\n",
      "Epoch 127/150\n",
      "249/253 [============================>.] - ETA: 0s - loss: 0.4399 - accuracy: 0.8346\n",
      "Epoch 127: val_loss did not improve from 0.34290\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4389 - accuracy: 0.8349 - val_loss: 0.3482 - val_accuracy: 0.8738\n",
      "Epoch 128/150\n",
      "238/253 [===========================>..] - ETA: 0s - loss: 0.4285 - accuracy: 0.8428\n",
      "Epoch 128: val_loss improved from 0.34290 to 0.34148, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4324 - accuracy: 0.8412 - val_loss: 0.3415 - val_accuracy: 0.8738\n",
      "Epoch 129/150\n",
      "231/253 [==========================>...] - ETA: 0s - loss: 0.4405 - accuracy: 0.8331\n",
      "Epoch 129: val_loss did not improve from 0.34148\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4397 - accuracy: 0.8342 - val_loss: 0.3504 - val_accuracy: 0.8706\n",
      "Epoch 130/150\n",
      "244/253 [===========================>..] - ETA: 0s - loss: 0.4380 - accuracy: 0.8404\n",
      "Epoch 130: val_loss did not improve from 0.34148\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4391 - accuracy: 0.8398 - val_loss: 0.3505 - val_accuracy: 0.8651\n",
      "Epoch 131/150\n",
      "251/253 [============================>.] - ETA: 0s - loss: 0.4406 - accuracy: 0.8380\n",
      "Epoch 131: val_loss did not improve from 0.34148\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4412 - accuracy: 0.8379 - val_loss: 0.3490 - val_accuracy: 0.8728\n",
      "Epoch 132/150\n",
      "241/253 [===========================>..] - ETA: 0s - loss: 0.4349 - accuracy: 0.8382\n",
      "Epoch 132: val_loss did not improve from 0.34148\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4362 - accuracy: 0.8375 - val_loss: 0.3418 - val_accuracy: 0.8755\n",
      "Epoch 133/150\n",
      "243/253 [===========================>..] - ETA: 0s - loss: 0.4389 - accuracy: 0.8366\n",
      "Epoch 133: val_loss did not improve from 0.34148\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4373 - accuracy: 0.8372 - val_loss: 0.3441 - val_accuracy: 0.8706\n",
      "Epoch 134/150\n",
      "248/253 [============================>.] - ETA: 0s - loss: 0.4330 - accuracy: 0.8390\n",
      "Epoch 134: val_loss did not improve from 0.34148\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4339 - accuracy: 0.8386 - val_loss: 0.3443 - val_accuracy: 0.8681\n",
      "Epoch 135/150\n",
      "252/253 [============================>.] - ETA: 0s - loss: 0.4392 - accuracy: 0.8362\n",
      "Epoch 135: val_loss improved from 0.34148 to 0.33566, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4392 - accuracy: 0.8362 - val_loss: 0.3357 - val_accuracy: 0.8782\n",
      "Epoch 136/150\n",
      "238/253 [===========================>..] - ETA: 0s - loss: 0.4295 - accuracy: 0.8371\n",
      "Epoch 136: val_loss did not improve from 0.33566\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4309 - accuracy: 0.8370 - val_loss: 0.3399 - val_accuracy: 0.8720\n",
      "Epoch 137/150\n",
      "245/253 [============================>.] - ETA: 0s - loss: 0.4424 - accuracy: 0.8368\n",
      "Epoch 137: val_loss did not improve from 0.33566\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4421 - accuracy: 0.8367 - val_loss: 0.3409 - val_accuracy: 0.8814\n",
      "Epoch 138/150\n",
      "241/253 [===========================>..] - ETA: 0s - loss: 0.4404 - accuracy: 0.8354\n",
      "Epoch 138: val_loss did not improve from 0.33566\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4413 - accuracy: 0.8345 - val_loss: 0.3442 - val_accuracy: 0.8708\n",
      "Epoch 139/150\n",
      "251/253 [============================>.] - ETA: 0s - loss: 0.4283 - accuracy: 0.8452\n",
      "Epoch 139: val_loss did not improve from 0.33566\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4282 - accuracy: 0.8454 - val_loss: 0.3367 - val_accuracy: 0.8735\n",
      "Epoch 140/150\n",
      "245/253 [============================>.] - ETA: 0s - loss: 0.4304 - accuracy: 0.8366\n",
      "Epoch 140: val_loss did not improve from 0.33566\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4293 - accuracy: 0.8368 - val_loss: 0.3436 - val_accuracy: 0.8765\n",
      "Epoch 141/150\n",
      "242/253 [===========================>..] - ETA: 0s - loss: 0.4295 - accuracy: 0.8410\n",
      "Epoch 141: val_loss did not improve from 0.33566\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4302 - accuracy: 0.8407 - val_loss: 0.3414 - val_accuracy: 0.8738\n",
      "Epoch 142/150\n",
      "247/253 [============================>.] - ETA: 0s - loss: 0.4331 - accuracy: 0.8396\n",
      "Epoch 142: val_loss did not improve from 0.33566\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4355 - accuracy: 0.8388 - val_loss: 0.3421 - val_accuracy: 0.8790\n",
      "Epoch 143/150\n",
      "243/253 [===========================>..] - ETA: 0s - loss: 0.4328 - accuracy: 0.8380\n",
      "Epoch 143: val_loss did not improve from 0.33566\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4339 - accuracy: 0.8379 - val_loss: 0.3357 - val_accuracy: 0.8760\n",
      "Epoch 144/150\n",
      "242/253 [===========================>..] - ETA: 0s - loss: 0.4292 - accuracy: 0.8429\n",
      "Epoch 144: val_loss improved from 0.33566 to 0.32693, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4277 - accuracy: 0.8435 - val_loss: 0.3269 - val_accuracy: 0.8824\n",
      "Epoch 145/150\n",
      "249/253 [============================>.] - ETA: 0s - loss: 0.4301 - accuracy: 0.8392\n",
      "Epoch 145: val_loss did not improve from 0.32693\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4303 - accuracy: 0.8393 - val_loss: 0.3283 - val_accuracy: 0.8765\n",
      "Epoch 146/150\n",
      "242/253 [===========================>..] - ETA: 0s - loss: 0.4283 - accuracy: 0.8404\n",
      "Epoch 146: val_loss improved from 0.32693 to 0.32564, saving model to saved_models\\audio_classification.hdf5\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4282 - accuracy: 0.8401 - val_loss: 0.3256 - val_accuracy: 0.8817\n",
      "Epoch 147/150\n",
      "247/253 [============================>.] - ETA: 0s - loss: 0.4352 - accuracy: 0.8386\n",
      "Epoch 147: val_loss did not improve from 0.32564\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4356 - accuracy: 0.8384 - val_loss: 0.3340 - val_accuracy: 0.8802\n",
      "Epoch 148/150\n",
      "245/253 [============================>.] - ETA: 0s - loss: 0.4261 - accuracy: 0.8422\n",
      "Epoch 148: val_loss did not improve from 0.32564\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4277 - accuracy: 0.8419 - val_loss: 0.3348 - val_accuracy: 0.8765\n",
      "Epoch 149/150\n",
      "241/253 [===========================>..] - ETA: 0s - loss: 0.4267 - accuracy: 0.8415\n",
      "Epoch 149: val_loss did not improve from 0.32564\n",
      "253/253 [==============================] - 1s 3ms/step - loss: 0.4264 - accuracy: 0.8413 - val_loss: 0.3353 - val_accuracy: 0.8787\n",
      "Epoch 150/150\n",
      "251/253 [============================>.] - ETA: 0s - loss: 0.4175 - accuracy: 0.8456\n",
      "Epoch 150: val_loss did not improve from 0.32564\n",
      "253/253 [==============================] - 1s 2ms/step - loss: 0.4180 - accuracy: 0.8456 - val_loss: 0.3362 - val_accuracy: 0.8777\n",
      "Training completed in time:  0:01:37.420704\n"
     ]
    }
   ],
   "source": [
    "## Trianing my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 150\n",
    "num_batch_size = 64\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, Y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8777173757553101\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,Y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.866847813129425"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.866847813129425"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming you have a trained model object named 'model'\n",
    "# Save the model to a file using pickle\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from tensorflow import keras\n",
    "\n",
    "# Assuming you have a trained Keras model object named 'model'\n",
    "# Save the model to an HDF5 file\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 251, in assert_input_compatibility\n        f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n       inputs=tf.Tensor(shape=(None,), dtype=float32)\n       training=False\n       mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15732\\1996584706.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_audio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:/Projects/MoodMate/test_copy/anger.wav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_audio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\sudha\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 251, in assert_input_compatibility\n        f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected min_ndim=2, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n       inputs=tf.Tensor(shape=(None,), dtype=float32)\n       training=False\n       mask=None\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('model.h5')\n",
    "test_audio=features_extractor(\"D:/Projects/MoodMate/test_copy/anger.wav\")\n",
    "predictions = model.predict(test_audio)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
